{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥-러닝 과정 CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EA1u4vCXxyz"
   },
   "source": [
    "### 첫번째 실습. Keras 모델 생성/학습 - MNIST : MLP\n",
    "[Keras Dataset](https://keras.io/ko/datasets/#mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9TIg2lB4Xxy2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 불러오기\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MmGb35gTXxzD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff832955640>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. 이미지 데이터 확인하기 🖼\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.imshow(x_train[90], cmap=plt.cm.gray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nosoxNNjXxzP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# 3-1. 이미지 데이터 전처리 : 2차원->1차원 🌟🌟🌟 => 2차원은 dense레이어에 인풋으로 사용할수 없어서\n",
    "\n",
    "x_train = x_train.reshape(60000,28*28)\n",
    "x_test = x_test.reshape(10000,28*28)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
       "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
       "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
       "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
       "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
       "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
       "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
       "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-1. 이미지 데이터 전처리 : 2차원->1차원 🌟🌟🌟\n",
    "\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YfiCskEHXxzT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
      " 0.49411765 0.53333333 0.68627451 0.10196078 0.65098039 1.\n",
      " 0.96862745 0.49803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      " 0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19215686\n",
      " 0.93333333 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.98431373 0.36470588 0.32156863\n",
      " 0.32156863 0.21960784 0.15294118 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07058824 0.85882353 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.77647059 0.71372549\n",
      " 0.96862745 0.94509804 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      " 0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05490196 0.00392157 0.60392157 0.99215686 0.35294118\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.54509804 0.99215686 0.74509804 0.00784314 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04313725\n",
      " 0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.1372549  0.94509804\n",
      " 0.88235294 0.62745098 0.42352941 0.00392157 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31764706 0.94117647 0.99215686\n",
      " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      " 0.58823529 0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0627451  0.36470588 0.98823529 0.99215686 0.73333333\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.97647059 0.99215686 0.97647059 0.25098039 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      " 0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15294118 0.58039216\n",
      " 0.89803922 0.99215686 0.99215686 0.99215686 0.98039216 0.71372549\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09411765 0.44705882 0.86666667 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.78823529 0.30588235 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07058824 0.67058824\n",
      " 0.85882353 0.99215686 0.99215686 0.99215686 0.99215686 0.76470588\n",
      " 0.31372549 0.03529412 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21568627 0.6745098  0.88627451 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.95686275 0.52156863 0.04313725 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53333333 0.99215686\n",
      " 0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# 3-2. 이미지 데이터 전처리 : Normalzation => 값이 너무 커져서 오버플로우가 발생할 수 있기 때문에\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TKtO7TUoXxzX"
   },
   "outputs": [],
   "source": [
    "# 4. Label 전처리 (one-hot encoding) \n",
    "import tensorflow as tf\n",
    "from tensorflow import one_hot\n",
    "\n",
    "#y_train = tf.one_hot(y_train, depth=10)\n",
    "#print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "#pd.get_dummies(y_train)\n",
    "#pd.get_dummies(y_test)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "\n",
    "# 반드시 한번만 실행하슈. 아니면 데이터 꼬일수 있음\n",
    "y_train = utils.to_categorical(y_train, 10)\n",
    "y_test = utils.to_categorical(y_test, 10)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbn2UpioXxzc"
   },
   "outputs": [],
   "source": [
    "# 5. 모델 생성 : MLP\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "model = keras.Sequential()\n",
    "# input_shape=x_train[0].shape으로 사용해도 됨.\n",
    "model.add(layers.Dense(input_dim=x_train.shape[1], units=256, activation='relu'))\n",
    "model.add(layers.Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(units=64, activation='relu'))\n",
    "model.add(layers.Dense(units=64, activation='relu',kernel_regularizer=keras.regularizers.L2(0.1)))\n",
    "model.add(layers.Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "octZbMRKXxzf"
   },
   "outputs": [],
   "source": [
    "# 6. Compile - Optimizer, Loss function 설정\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# 빠른 종료\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnZlXtfUXxzj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 7. 모델 학습시키기\n",
    "\n",
    "#hist = model.fit(x_train,y_train,validation_data=(x_val, y_val), batch_size=4,epochs=200,verbose=1,validation_split=0.1,callbacks=[early_stopping,modelcheckpiing])\n",
    "hist = model.fit(x_train,y_train,batch_size=100,epochs=20,validation_split=0.2,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pgYRoXaJXxzn"
   },
   "outputs": [],
   "source": [
    "# 8. 모델 평가하기\n",
    "model.evaluate(x_train, y_train)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7kPGgJEXxzv"
   },
   "outputs": [],
   "source": [
    "# 9. 학습 시각화하기\n",
    "\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLhicf8aXxzr",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 10. 이미지를 랜덤으로 선택해 훈련된 모델로 예측 🖼\n",
    "\n",
    "import numpy as np\n",
    "for index in np.random.choice(len(y_test), 3, replace = False):\n",
    "    test_image = x_test[index].reshape(1, 784)\n",
    "    predicted = model.predict(test_image)\n",
    "    label = y_test[index]\n",
    "    result_label = np.where(label == np.amax(label))\n",
    "    result_predicted = np.where(predicted == np.amax(predicted))\n",
    "    title = \"Label value = %s  Predicted value = %s \" % (label, result_predicted[1])\n",
    "    \n",
    "    fig = plt.figure(1, figsize = (3,3))\n",
    "    ax1 = fig.add_axes((0,0,.8,.8))\n",
    "    ax1.set_title(title)\n",
    "    images = x_test\n",
    "    plt.imshow(images[index].reshape(28, 28), cmap = plt.cm.gray, interpolation = 'nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01.MNIST_MLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py38_tensorflow",
   "language": "python",
   "name": "conda-env-py38_tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
