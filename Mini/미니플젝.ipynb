{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "from numpy.fft import fft, fftshift\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "from scipy.integrate import cumtrapz\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "print(tf.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('./train_features.csv')\n",
    "train_labels=pd.read_csv('./train_labels.csv')\n",
    "test=pd.read_csv('./test_features.csv')\n",
    "\n",
    "submission=pd.read_csv('./sample_submission.csv')\n",
    "\n",
    "pd.options.display.max_columns=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875000, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engneering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  가속도, 자이로, (자이로-가속도) 센서값을 에너지로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['acc_Energy']=(train['acc_x']**2+train['acc_y']**2+train['acc_z']**2)**(1/3)\n",
    "test['acc_Energy']=(test['acc_x']**2+test['acc_y']**2+test['acc_z']**2)**(1/3)\n",
    "\n",
    "train['gy_Energy']=(train['gy_x']**2+train['gy_y']**2+train['gy_z']**2)**(1/3)\n",
    "test['gy_Energy']=(test['gy_x']**2+test['gy_y']**2+test['gy_z']**2)**(1/3)\n",
    "\n",
    "train['gy_acc_Energy']=((train['gy_x']-train['acc_x'])**2+(train['gy_y']-train['acc_y'])**2+(train['gy_z']-train['acc_z'])**2)**(1/3)\n",
    "test['gy_acc_Energy']=((test['gy_x']-test['acc_x'])**2+(test['gy_y']-test['acc_y'])**2+(test['gy_z']-test['acc_z'])**2)**(1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875000, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### id별 데이터는 0.02초마다 측정된 값들이기 때문에 이전 시간 대비 변화량 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=0.02 \n",
    "def jerk_signal(signal): \n",
    "        return np.array([(signal[i+1]-signal[i])/dt for i in range(len(signal)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [00:43<00:00, 72.49it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dt=[]\n",
    "for i in tqdm(train['id'].unique()):\n",
    "    temp=train.loc[train['id']==i]\n",
    "    for v in train.columns[2:]:\n",
    "        values=jerk_signal(temp[v].values)\n",
    "        values=np.insert(values,0,0)\n",
    "        temp.loc[:,v+'_dt']=values\n",
    "    train_dt.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:09<00:00, 83.58it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dt=[]\n",
    "for i in tqdm(test['id'].unique()):\n",
    "    temp=test.loc[test['id']==i]\n",
    "    for v in train.columns[2:]:\n",
    "        values=jerk_signal(temp[v].values)\n",
    "        values=np.insert(values,0,0)\n",
    "        temp.loc[:,v+'_dt']=values\n",
    "    test_dt.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fftpack\n",
    "from numpy.fft import *\n",
    "\n",
    "def fourier_transform_one_signal(t_signal):\n",
    "    complex_f_signal= fftpack.fft(t_signal)\n",
    "    amplitude_f_signal=np.abs(complex_f_signal)\n",
    "    return amplitude_f_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_Energy</th>\n",
       "      <th>gy_Energy</th>\n",
       "      <th>gy_acc_Energy</th>\n",
       "      <th>acc_x_dt</th>\n",
       "      <th>acc_y_dt</th>\n",
       "      <th>acc_z_dt</th>\n",
       "      <th>gy_x_dt</th>\n",
       "      <th>gy_y_dt</th>\n",
       "      <th>gy_z_dt</th>\n",
       "      <th>acc_Energy_dt</th>\n",
       "      <th>gy_Energy_dt</th>\n",
       "      <th>gy_acc_Energy_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.206087</td>\n",
       "      <td>-0.179371</td>\n",
       "      <td>-0.148447</td>\n",
       "      <td>-0.591608</td>\n",
       "      <td>-30.549010</td>\n",
       "      <td>-31.676112</td>\n",
       "      <td>1.146962</td>\n",
       "      <td>12.465436</td>\n",
       "      <td>12.427938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.287696</td>\n",
       "      <td>-0.198974</td>\n",
       "      <td>-0.182444</td>\n",
       "      <td>0.303100</td>\n",
       "      <td>-39.139103</td>\n",
       "      <td>-24.927216</td>\n",
       "      <td>1.200703</td>\n",
       "      <td>12.913284</td>\n",
       "      <td>12.865692</td>\n",
       "      <td>4.080495</td>\n",
       "      <td>-0.980114</td>\n",
       "      <td>-1.699854</td>\n",
       "      <td>44.735403</td>\n",
       "      <td>-429.504677</td>\n",
       "      <td>337.444793</td>\n",
       "      <td>2.687024</td>\n",
       "      <td>22.392358</td>\n",
       "      <td>21.887693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.304609</td>\n",
       "      <td>-0.195114</td>\n",
       "      <td>-0.253382</td>\n",
       "      <td>-3.617278</td>\n",
       "      <td>-44.122565</td>\n",
       "      <td>-25.019629</td>\n",
       "      <td>1.217403</td>\n",
       "      <td>13.725729</td>\n",
       "      <td>13.692643</td>\n",
       "      <td>0.845632</td>\n",
       "      <td>0.192961</td>\n",
       "      <td>-3.546937</td>\n",
       "      <td>-196.018888</td>\n",
       "      <td>-249.173073</td>\n",
       "      <td>-4.620631</td>\n",
       "      <td>0.835012</td>\n",
       "      <td>40.622253</td>\n",
       "      <td>41.347563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.293095</td>\n",
       "      <td>-0.230366</td>\n",
       "      <td>-0.215210</td>\n",
       "      <td>2.712986</td>\n",
       "      <td>-53.597843</td>\n",
       "      <td>-27.454013</td>\n",
       "      <td>1.209981</td>\n",
       "      <td>15.374021</td>\n",
       "      <td>15.314907</td>\n",
       "      <td>-0.575711</td>\n",
       "      <td>-1.762585</td>\n",
       "      <td>1.908626</td>\n",
       "      <td>316.513181</td>\n",
       "      <td>-473.763910</td>\n",
       "      <td>-121.719195</td>\n",
       "      <td>-0.371100</td>\n",
       "      <td>82.414636</td>\n",
       "      <td>81.113199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.300887</td>\n",
       "      <td>-0.187757</td>\n",
       "      <td>-0.222523</td>\n",
       "      <td>4.286707</td>\n",
       "      <td>-57.906561</td>\n",
       "      <td>-27.961234</td>\n",
       "      <td>1.211254</td>\n",
       "      <td>16.074363</td>\n",
       "      <td>16.017964</td>\n",
       "      <td>0.389598</td>\n",
       "      <td>2.130453</td>\n",
       "      <td>-0.365665</td>\n",
       "      <td>78.686055</td>\n",
       "      <td>-215.435892</td>\n",
       "      <td>-25.361098</td>\n",
       "      <td>0.063656</td>\n",
       "      <td>35.017060</td>\n",
       "      <td>35.152822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874995</th>\n",
       "      <td>3124</td>\n",
       "      <td>595</td>\n",
       "      <td>-0.712530</td>\n",
       "      <td>-0.658357</td>\n",
       "      <td>0.293707</td>\n",
       "      <td>-29.367857</td>\n",
       "      <td>-104.013664</td>\n",
       "      <td>-76.290437</td>\n",
       "      <td>1.009050</td>\n",
       "      <td>25.963234</td>\n",
       "      <td>25.897316</td>\n",
       "      <td>1.484646</td>\n",
       "      <td>0.303666</td>\n",
       "      <td>0.800069</td>\n",
       "      <td>-150.644663</td>\n",
       "      <td>-34.630282</td>\n",
       "      <td>-8.380088</td>\n",
       "      <td>-0.679712</td>\n",
       "      <td>8.387109</td>\n",
       "      <td>8.432977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874996</th>\n",
       "      <td>3124</td>\n",
       "      <td>596</td>\n",
       "      <td>-0.683037</td>\n",
       "      <td>-0.658466</td>\n",
       "      <td>0.329223</td>\n",
       "      <td>-30.149089</td>\n",
       "      <td>-101.796809</td>\n",
       "      <td>-76.625087</td>\n",
       "      <td>1.002827</td>\n",
       "      <td>25.784692</td>\n",
       "      <td>25.722482</td>\n",
       "      <td>1.474659</td>\n",
       "      <td>-0.005442</td>\n",
       "      <td>1.775771</td>\n",
       "      <td>-39.061611</td>\n",
       "      <td>110.842743</td>\n",
       "      <td>-16.732496</td>\n",
       "      <td>-0.311171</td>\n",
       "      <td>-8.927089</td>\n",
       "      <td>-8.741727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874997</th>\n",
       "      <td>3124</td>\n",
       "      <td>597</td>\n",
       "      <td>-0.664730</td>\n",
       "      <td>-0.666625</td>\n",
       "      <td>0.364114</td>\n",
       "      <td>-27.873095</td>\n",
       "      <td>-98.776072</td>\n",
       "      <td>-79.365125</td>\n",
       "      <td>1.006239</td>\n",
       "      <td>25.628060</td>\n",
       "      <td>25.572145</td>\n",
       "      <td>0.915321</td>\n",
       "      <td>-0.407957</td>\n",
       "      <td>1.744566</td>\n",
       "      <td>113.799702</td>\n",
       "      <td>151.036858</td>\n",
       "      <td>-137.001896</td>\n",
       "      <td>0.170620</td>\n",
       "      <td>-7.831611</td>\n",
       "      <td>-7.516832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874998</th>\n",
       "      <td>3124</td>\n",
       "      <td>598</td>\n",
       "      <td>-0.630534</td>\n",
       "      <td>-0.682565</td>\n",
       "      <td>0.373696</td>\n",
       "      <td>-23.636550</td>\n",
       "      <td>-99.139495</td>\n",
       "      <td>-80.259478</td>\n",
       "      <td>1.001038</td>\n",
       "      <td>25.626266</td>\n",
       "      <td>25.573288</td>\n",
       "      <td>1.709833</td>\n",
       "      <td>-0.796984</td>\n",
       "      <td>0.479107</td>\n",
       "      <td>211.827245</td>\n",
       "      <td>-18.171144</td>\n",
       "      <td>-44.717652</td>\n",
       "      <td>-0.260074</td>\n",
       "      <td>-0.089713</td>\n",
       "      <td>0.057150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874999</th>\n",
       "      <td>3124</td>\n",
       "      <td>599</td>\n",
       "      <td>-0.578351</td>\n",
       "      <td>-0.700235</td>\n",
       "      <td>0.384390</td>\n",
       "      <td>-17.917626</td>\n",
       "      <td>-100.181873</td>\n",
       "      <td>-80.676229</td>\n",
       "      <td>0.990773</td>\n",
       "      <td>25.645131</td>\n",
       "      <td>25.595348</td>\n",
       "      <td>2.609116</td>\n",
       "      <td>-0.883512</td>\n",
       "      <td>0.534668</td>\n",
       "      <td>285.946217</td>\n",
       "      <td>-52.118894</td>\n",
       "      <td>-20.837588</td>\n",
       "      <td>-0.513215</td>\n",
       "      <td>0.943240</td>\n",
       "      <td>1.102985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1875000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  time     acc_x     acc_y     acc_z       gy_x        gy_y  \\\n",
       "0           0     0  1.206087 -0.179371 -0.148447  -0.591608  -30.549010   \n",
       "1           0     1  1.287696 -0.198974 -0.182444   0.303100  -39.139103   \n",
       "2           0     2  1.304609 -0.195114 -0.253382  -3.617278  -44.122565   \n",
       "3           0     3  1.293095 -0.230366 -0.215210   2.712986  -53.597843   \n",
       "4           0     4  1.300887 -0.187757 -0.222523   4.286707  -57.906561   \n",
       "...       ...   ...       ...       ...       ...        ...         ...   \n",
       "1874995  3124   595 -0.712530 -0.658357  0.293707 -29.367857 -104.013664   \n",
       "1874996  3124   596 -0.683037 -0.658466  0.329223 -30.149089 -101.796809   \n",
       "1874997  3124   597 -0.664730 -0.666625  0.364114 -27.873095  -98.776072   \n",
       "1874998  3124   598 -0.630534 -0.682565  0.373696 -23.636550  -99.139495   \n",
       "1874999  3124   599 -0.578351 -0.700235  0.384390 -17.917626 -100.181873   \n",
       "\n",
       "              gy_z  acc_Energy  gy_Energy  gy_acc_Energy  acc_x_dt  acc_y_dt  \\\n",
       "0       -31.676112    1.146962  12.465436      12.427938  0.000000  0.000000   \n",
       "1       -24.927216    1.200703  12.913284      12.865692  4.080495 -0.980114   \n",
       "2       -25.019629    1.217403  13.725729      13.692643  0.845632  0.192961   \n",
       "3       -27.454013    1.209981  15.374021      15.314907 -0.575711 -1.762585   \n",
       "4       -27.961234    1.211254  16.074363      16.017964  0.389598  2.130453   \n",
       "...            ...         ...        ...            ...       ...       ...   \n",
       "1874995 -76.290437    1.009050  25.963234      25.897316  1.484646  0.303666   \n",
       "1874996 -76.625087    1.002827  25.784692      25.722482  1.474659 -0.005442   \n",
       "1874997 -79.365125    1.006239  25.628060      25.572145  0.915321 -0.407957   \n",
       "1874998 -80.259478    1.001038  25.626266      25.573288  1.709833 -0.796984   \n",
       "1874999 -80.676229    0.990773  25.645131      25.595348  2.609116 -0.883512   \n",
       "\n",
       "         acc_z_dt     gy_x_dt     gy_y_dt     gy_z_dt  acc_Energy_dt  \\\n",
       "0        0.000000    0.000000    0.000000    0.000000       0.000000   \n",
       "1       -1.699854   44.735403 -429.504677  337.444793       2.687024   \n",
       "2       -3.546937 -196.018888 -249.173073   -4.620631       0.835012   \n",
       "3        1.908626  316.513181 -473.763910 -121.719195      -0.371100   \n",
       "4       -0.365665   78.686055 -215.435892  -25.361098       0.063656   \n",
       "...           ...         ...         ...         ...            ...   \n",
       "1874995  0.800069 -150.644663  -34.630282   -8.380088      -0.679712   \n",
       "1874996  1.775771  -39.061611  110.842743  -16.732496      -0.311171   \n",
       "1874997  1.744566  113.799702  151.036858 -137.001896       0.170620   \n",
       "1874998  0.479107  211.827245  -18.171144  -44.717652      -0.260074   \n",
       "1874999  0.534668  285.946217  -52.118894  -20.837588      -0.513215   \n",
       "\n",
       "         gy_Energy_dt  gy_acc_Energy_dt  \n",
       "0            0.000000          0.000000  \n",
       "1           22.392358         21.887693  \n",
       "2           40.622253         41.347563  \n",
       "3           82.414636         81.113199  \n",
       "4           35.017060         35.152822  \n",
       "...               ...               ...  \n",
       "1874995      8.387109          8.432977  \n",
       "1874996     -8.927089         -8.741727  \n",
       "1874997     -7.831611         -7.516832  \n",
       "1874998     -0.089713          0.057150  \n",
       "1874999      0.943240          1.102985  \n",
       "\n",
       "[1875000 rows x 20 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.concat(train_dt)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [00:11<00:00, 273.28it/s]\n"
     ]
    }
   ],
   "source": [
    "fft=[]\n",
    "for i in tqdm(train['id'].unique()):\n",
    "    temp=train.loc[train['id']==i]\n",
    "    for i in train.columns[2:8]:\n",
    "        temp[i]=fourier_transform_one_signal(temp[i].values)\n",
    "    fft.append(temp)\n",
    "train=pd.concat(fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_Energy</th>\n",
       "      <th>gy_Energy</th>\n",
       "      <th>gy_acc_Energy</th>\n",
       "      <th>acc_x_dt</th>\n",
       "      <th>acc_y_dt</th>\n",
       "      <th>acc_z_dt</th>\n",
       "      <th>gy_x_dt</th>\n",
       "      <th>gy_y_dt</th>\n",
       "      <th>gy_z_dt</th>\n",
       "      <th>acc_Energy_dt</th>\n",
       "      <th>gy_Energy_dt</th>\n",
       "      <th>gy_acc_Energy_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3125</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.628100</td>\n",
       "      <td>-0.160155</td>\n",
       "      <td>0.151487</td>\n",
       "      <td>49.665357</td>\n",
       "      <td>88.435961</td>\n",
       "      <td>13.597668</td>\n",
       "      <td>0.762377</td>\n",
       "      <td>21.878437</td>\n",
       "      <td>21.938882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3125</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.462548</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>-0.053726</td>\n",
       "      <td>56.953059</td>\n",
       "      <td>96.185341</td>\n",
       "      <td>16.278458</td>\n",
       "      <td>0.600917</td>\n",
       "      <td>23.367908</td>\n",
       "      <td>23.399763</td>\n",
       "      <td>8.277606</td>\n",
       "      <td>8.630860</td>\n",
       "      <td>-10.260605</td>\n",
       "      <td>364.385137</td>\n",
       "      <td>387.469010</td>\n",
       "      <td>134.039504</td>\n",
       "      <td>-8.072977</td>\n",
       "      <td>74.473561</td>\n",
       "      <td>73.044041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3125</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.363481</td>\n",
       "      <td>-0.091789</td>\n",
       "      <td>-0.130004</td>\n",
       "      <td>29.557396</td>\n",
       "      <td>93.836453</td>\n",
       "      <td>13.329043</td>\n",
       "      <td>0.539978</td>\n",
       "      <td>21.440856</td>\n",
       "      <td>21.471510</td>\n",
       "      <td>4.953330</td>\n",
       "      <td>-5.212527</td>\n",
       "      <td>-3.813919</td>\n",
       "      <td>-1369.783175</td>\n",
       "      <td>-117.444408</td>\n",
       "      <td>-147.470749</td>\n",
       "      <td>-3.046963</td>\n",
       "      <td>-96.352572</td>\n",
       "      <td>-96.412634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3125</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.351750</td>\n",
       "      <td>-0.239870</td>\n",
       "      <td>-0.193053</td>\n",
       "      <td>23.686172</td>\n",
       "      <td>88.608721</td>\n",
       "      <td>13.449771</td>\n",
       "      <td>0.602338</td>\n",
       "      <td>20.482783</td>\n",
       "      <td>20.533967</td>\n",
       "      <td>0.586560</td>\n",
       "      <td>-7.404041</td>\n",
       "      <td>-3.152460</td>\n",
       "      <td>-293.561181</td>\n",
       "      <td>-261.386607</td>\n",
       "      <td>6.036401</td>\n",
       "      <td>3.118006</td>\n",
       "      <td>-47.903682</td>\n",
       "      <td>-46.877152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3125</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.312934</td>\n",
       "      <td>-0.123762</td>\n",
       "      <td>-0.318621</td>\n",
       "      <td>20.410071</td>\n",
       "      <td>85.327707</td>\n",
       "      <td>13.884912</td>\n",
       "      <td>0.598853</td>\n",
       "      <td>19.908061</td>\n",
       "      <td>19.944125</td>\n",
       "      <td>1.940804</td>\n",
       "      <td>5.805371</td>\n",
       "      <td>-6.278395</td>\n",
       "      <td>-163.805080</td>\n",
       "      <td>-164.050703</td>\n",
       "      <td>21.757050</td>\n",
       "      <td>-0.174231</td>\n",
       "      <td>-28.736096</td>\n",
       "      <td>-29.492133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469195</th>\n",
       "      <td>3906</td>\n",
       "      <td>595</td>\n",
       "      <td>0.104191</td>\n",
       "      <td>-0.784979</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>-10.475346</td>\n",
       "      <td>14.095361</td>\n",
       "      <td>-190.358982</td>\n",
       "      <td>1.011867</td>\n",
       "      <td>33.185050</td>\n",
       "      <td>33.266220</td>\n",
       "      <td>-3.361947</td>\n",
       "      <td>3.580749</td>\n",
       "      <td>0.006738</td>\n",
       "      <td>-771.499131</td>\n",
       "      <td>-849.527466</td>\n",
       "      <td>-8.671145</td>\n",
       "      <td>-2.122263</td>\n",
       "      <td>-9.277974</td>\n",
       "      <td>-9.636798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469196</th>\n",
       "      <td>3906</td>\n",
       "      <td>596</td>\n",
       "      <td>0.103297</td>\n",
       "      <td>-0.758954</td>\n",
       "      <td>0.615687</td>\n",
       "      <td>-25.360272</td>\n",
       "      <td>-8.523018</td>\n",
       "      <td>-180.393291</td>\n",
       "      <td>0.988451</td>\n",
       "      <td>32.158563</td>\n",
       "      <td>32.227841</td>\n",
       "      <td>-0.044724</td>\n",
       "      <td>1.301266</td>\n",
       "      <td>-1.191327</td>\n",
       "      <td>-744.246300</td>\n",
       "      <td>-1130.918984</td>\n",
       "      <td>498.284561</td>\n",
       "      <td>-1.170808</td>\n",
       "      <td>-51.324317</td>\n",
       "      <td>-51.918937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469197</th>\n",
       "      <td>3906</td>\n",
       "      <td>597</td>\n",
       "      <td>0.128294</td>\n",
       "      <td>-0.749389</td>\n",
       "      <td>0.586184</td>\n",
       "      <td>-27.917723</td>\n",
       "      <td>-23.186245</td>\n",
       "      <td>-162.624160</td>\n",
       "      <td>0.973171</td>\n",
       "      <td>30.280197</td>\n",
       "      <td>30.339698</td>\n",
       "      <td>1.249868</td>\n",
       "      <td>0.478247</td>\n",
       "      <td>-1.475149</td>\n",
       "      <td>-127.872573</td>\n",
       "      <td>-733.161359</td>\n",
       "      <td>888.456533</td>\n",
       "      <td>-0.763970</td>\n",
       "      <td>-93.918343</td>\n",
       "      <td>-94.407192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469198</th>\n",
       "      <td>3906</td>\n",
       "      <td>598</td>\n",
       "      <td>0.104130</td>\n",
       "      <td>-0.692731</td>\n",
       "      <td>0.573397</td>\n",
       "      <td>-27.847980</td>\n",
       "      <td>-30.407555</td>\n",
       "      <td>-138.761676</td>\n",
       "      <td>0.935801</td>\n",
       "      <td>27.569491</td>\n",
       "      <td>27.623600</td>\n",
       "      <td>-1.208173</td>\n",
       "      <td>2.832870</td>\n",
       "      <td>-0.639335</td>\n",
       "      <td>3.487160</td>\n",
       "      <td>-361.065463</td>\n",
       "      <td>1193.124196</td>\n",
       "      <td>-1.868499</td>\n",
       "      <td>-135.535264</td>\n",
       "      <td>-135.804895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469199</th>\n",
       "      <td>3906</td>\n",
       "      <td>599</td>\n",
       "      <td>0.059299</td>\n",
       "      <td>-0.613487</td>\n",
       "      <td>0.556780</td>\n",
       "      <td>-29.900725</td>\n",
       "      <td>-36.586219</td>\n",
       "      <td>-116.423810</td>\n",
       "      <td>0.883607</td>\n",
       "      <td>25.086160</td>\n",
       "      <td>25.133208</td>\n",
       "      <td>-2.241562</td>\n",
       "      <td>3.962233</td>\n",
       "      <td>-0.830861</td>\n",
       "      <td>-102.637249</td>\n",
       "      <td>-308.933221</td>\n",
       "      <td>1116.893337</td>\n",
       "      <td>-2.609723</td>\n",
       "      <td>-124.166545</td>\n",
       "      <td>-124.519564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469200 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  time     acc_x     acc_y     acc_z       gy_x       gy_y  \\\n",
       "0       3125     0 -0.628100 -0.160155  0.151487  49.665357  88.435961   \n",
       "1       3125     1 -0.462548  0.012462 -0.053726  56.953059  96.185341   \n",
       "2       3125     2 -0.363481 -0.091789 -0.130004  29.557396  93.836453   \n",
       "3       3125     3 -0.351750 -0.239870 -0.193053  23.686172  88.608721   \n",
       "4       3125     4 -0.312934 -0.123762 -0.318621  20.410071  85.327707   \n",
       "...      ...   ...       ...       ...       ...        ...        ...   \n",
       "469195  3906   595  0.104191 -0.784979  0.639513 -10.475346  14.095361   \n",
       "469196  3906   596  0.103297 -0.758954  0.615687 -25.360272  -8.523018   \n",
       "469197  3906   597  0.128294 -0.749389  0.586184 -27.917723 -23.186245   \n",
       "469198  3906   598  0.104130 -0.692731  0.573397 -27.847980 -30.407555   \n",
       "469199  3906   599  0.059299 -0.613487  0.556780 -29.900725 -36.586219   \n",
       "\n",
       "              gy_z  acc_Energy  gy_Energy  gy_acc_Energy  acc_x_dt  acc_y_dt  \\\n",
       "0        13.597668    0.762377  21.878437      21.938882  0.000000  0.000000   \n",
       "1        16.278458    0.600917  23.367908      23.399763  8.277606  8.630860   \n",
       "2        13.329043    0.539978  21.440856      21.471510  4.953330 -5.212527   \n",
       "3        13.449771    0.602338  20.482783      20.533967  0.586560 -7.404041   \n",
       "4        13.884912    0.598853  19.908061      19.944125  1.940804  5.805371   \n",
       "...            ...         ...        ...            ...       ...       ...   \n",
       "469195 -190.358982    1.011867  33.185050      33.266220 -3.361947  3.580749   \n",
       "469196 -180.393291    0.988451  32.158563      32.227841 -0.044724  1.301266   \n",
       "469197 -162.624160    0.973171  30.280197      30.339698  1.249868  0.478247   \n",
       "469198 -138.761676    0.935801  27.569491      27.623600 -1.208173  2.832870   \n",
       "469199 -116.423810    0.883607  25.086160      25.133208 -2.241562  3.962233   \n",
       "\n",
       "         acc_z_dt      gy_x_dt      gy_y_dt      gy_z_dt  acc_Energy_dt  \\\n",
       "0        0.000000     0.000000     0.000000     0.000000       0.000000   \n",
       "1      -10.260605   364.385137   387.469010   134.039504      -8.072977   \n",
       "2       -3.813919 -1369.783175  -117.444408  -147.470749      -3.046963   \n",
       "3       -3.152460  -293.561181  -261.386607     6.036401       3.118006   \n",
       "4       -6.278395  -163.805080  -164.050703    21.757050      -0.174231   \n",
       "...           ...          ...          ...          ...            ...   \n",
       "469195   0.006738  -771.499131  -849.527466    -8.671145      -2.122263   \n",
       "469196  -1.191327  -744.246300 -1130.918984   498.284561      -1.170808   \n",
       "469197  -1.475149  -127.872573  -733.161359   888.456533      -0.763970   \n",
       "469198  -0.639335     3.487160  -361.065463  1193.124196      -1.868499   \n",
       "469199  -0.830861  -102.637249  -308.933221  1116.893337      -2.609723   \n",
       "\n",
       "        gy_Energy_dt  gy_acc_Energy_dt  \n",
       "0           0.000000          0.000000  \n",
       "1          74.473561         73.044041  \n",
       "2         -96.352572        -96.412634  \n",
       "3         -47.903682        -46.877152  \n",
       "4         -28.736096        -29.492133  \n",
       "...              ...               ...  \n",
       "469195     -9.277974         -9.636798  \n",
       "469196    -51.324317        -51.918937  \n",
       "469197    -93.918343        -94.407192  \n",
       "469198   -135.535264       -135.804895  \n",
       "469199   -124.166545       -124.519564  \n",
       "\n",
       "[469200 rows x 20 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.concat(test_dt)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "col=train.columns\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train.iloc[:,2:]= scaler.fit_transform(train.iloc[:,2:])\n",
    "train = pd.DataFrame(data = train,columns =col)\n",
    "\n",
    "test.iloc[:,2:]= scaler.transform(test.iloc[:,2:])\n",
    "test = pd.DataFrame(data = test,columns =col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_Energy</th>\n",
       "      <th>gy_Energy</th>\n",
       "      <th>gy_acc_Energy</th>\n",
       "      <th>acc_x_dt</th>\n",
       "      <th>acc_y_dt</th>\n",
       "      <th>acc_z_dt</th>\n",
       "      <th>gy_x_dt</th>\n",
       "      <th>gy_y_dt</th>\n",
       "      <th>gy_z_dt</th>\n",
       "      <th>acc_Energy_dt</th>\n",
       "      <th>gy_Energy_dt</th>\n",
       "      <th>gy_acc_Energy_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.356382</td>\n",
       "      <td>8.807207</td>\n",
       "      <td>19.465910</td>\n",
       "      <td>0.376992</td>\n",
       "      <td>0.869226</td>\n",
       "      <td>0.150423</td>\n",
       "      <td>0.495681</td>\n",
       "      <td>-0.272719</td>\n",
       "      <td>-0.276391</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.001501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.054866</td>\n",
       "      <td>0.833464</td>\n",
       "      <td>0.820412</td>\n",
       "      <td>-0.282128</td>\n",
       "      <td>-0.093560</td>\n",
       "      <td>0.011266</td>\n",
       "      <td>0.742974</td>\n",
       "      <td>-0.236152</td>\n",
       "      <td>-0.240632</td>\n",
       "      <td>0.416836</td>\n",
       "      <td>-0.118821</td>\n",
       "      <td>-0.255054</td>\n",
       "      <td>0.032738</td>\n",
       "      <td>-0.349095</td>\n",
       "      <td>0.377085</td>\n",
       "      <td>0.564992</td>\n",
       "      <td>0.166566</td>\n",
       "      <td>0.162871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024046</td>\n",
       "      <td>0.315921</td>\n",
       "      <td>0.081086</td>\n",
       "      <td>-0.182551</td>\n",
       "      <td>-0.053585</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.819822</td>\n",
       "      <td>-0.169815</td>\n",
       "      <td>-0.173080</td>\n",
       "      <td>0.086405</td>\n",
       "      <td>0.023750</td>\n",
       "      <td>-0.531727</td>\n",
       "      <td>-0.141582</td>\n",
       "      <td>-0.202368</td>\n",
       "      <td>-0.004887</td>\n",
       "      <td>0.175645</td>\n",
       "      <td>0.300944</td>\n",
       "      <td>0.306341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.065632</td>\n",
       "      <td>0.117634</td>\n",
       "      <td>-0.040874</td>\n",
       "      <td>-0.194863</td>\n",
       "      <td>0.154242</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.785669</td>\n",
       "      <td>-0.035229</td>\n",
       "      <td>-0.040560</td>\n",
       "      <td>-0.058780</td>\n",
       "      <td>-0.213920</td>\n",
       "      <td>0.285459</td>\n",
       "      <td>0.229520</td>\n",
       "      <td>-0.385106</td>\n",
       "      <td>-0.135647</td>\n",
       "      <td>-0.077915</td>\n",
       "      <td>0.609008</td>\n",
       "      <td>0.599518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.151477</td>\n",
       "      <td>0.300751</td>\n",
       "      <td>0.317742</td>\n",
       "      <td>-0.350724</td>\n",
       "      <td>0.494539</td>\n",
       "      <td>0.154354</td>\n",
       "      <td>0.791528</td>\n",
       "      <td>0.021954</td>\n",
       "      <td>0.016872</td>\n",
       "      <td>0.039823</td>\n",
       "      <td>0.259227</td>\n",
       "      <td>-0.055206</td>\n",
       "      <td>0.057320</td>\n",
       "      <td>-0.174917</td>\n",
       "      <td>-0.028047</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>0.259626</td>\n",
       "      <td>0.260669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874995</th>\n",
       "      <td>3124</td>\n",
       "      <td>595</td>\n",
       "      <td>0.365037</td>\n",
       "      <td>0.011656</td>\n",
       "      <td>0.845701</td>\n",
       "      <td>0.080839</td>\n",
       "      <td>0.350395</td>\n",
       "      <td>0.112282</td>\n",
       "      <td>-0.138940</td>\n",
       "      <td>0.829394</td>\n",
       "      <td>0.823900</td>\n",
       "      <td>0.151679</td>\n",
       "      <td>0.037205</td>\n",
       "      <td>0.119409</td>\n",
       "      <td>-0.108728</td>\n",
       "      <td>-0.027804</td>\n",
       "      <td>-0.009085</td>\n",
       "      <td>-0.142794</td>\n",
       "      <td>0.063329</td>\n",
       "      <td>0.063674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874996</th>\n",
       "      <td>3124</td>\n",
       "      <td>596</td>\n",
       "      <td>10.220817</td>\n",
       "      <td>5.476964</td>\n",
       "      <td>7.441373</td>\n",
       "      <td>3.605246</td>\n",
       "      <td>16.530576</td>\n",
       "      <td>11.843241</td>\n",
       "      <td>-0.167578</td>\n",
       "      <td>0.814816</td>\n",
       "      <td>0.809618</td>\n",
       "      <td>0.150658</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>0.265559</td>\n",
       "      <td>-0.027936</td>\n",
       "      <td>0.090560</td>\n",
       "      <td>-0.018412</td>\n",
       "      <td>-0.065316</td>\n",
       "      <td>-0.064300</td>\n",
       "      <td>-0.062949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874997</th>\n",
       "      <td>3124</td>\n",
       "      <td>597</td>\n",
       "      <td>0.386337</td>\n",
       "      <td>0.177768</td>\n",
       "      <td>-0.080193</td>\n",
       "      <td>-0.192468</td>\n",
       "      <td>-0.033904</td>\n",
       "      <td>-0.227861</td>\n",
       "      <td>-0.151875</td>\n",
       "      <td>0.802027</td>\n",
       "      <td>0.797338</td>\n",
       "      <td>0.093524</td>\n",
       "      <td>-0.049283</td>\n",
       "      <td>0.260884</td>\n",
       "      <td>0.082744</td>\n",
       "      <td>0.123264</td>\n",
       "      <td>-0.152712</td>\n",
       "      <td>0.035970</td>\n",
       "      <td>-0.056225</td>\n",
       "      <td>-0.053918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874998</th>\n",
       "      <td>3124</td>\n",
       "      <td>598</td>\n",
       "      <td>0.728823</td>\n",
       "      <td>0.014037</td>\n",
       "      <td>0.350745</td>\n",
       "      <td>0.136284</td>\n",
       "      <td>1.281790</td>\n",
       "      <td>0.403540</td>\n",
       "      <td>-0.175811</td>\n",
       "      <td>0.801880</td>\n",
       "      <td>0.797431</td>\n",
       "      <td>0.174681</td>\n",
       "      <td>-0.096564</td>\n",
       "      <td>0.071332</td>\n",
       "      <td>0.153722</td>\n",
       "      <td>-0.014412</td>\n",
       "      <td>-0.049662</td>\n",
       "      <td>-0.054574</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.001922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874999</th>\n",
       "      <td>3124</td>\n",
       "      <td>599</td>\n",
       "      <td>0.886204</td>\n",
       "      <td>0.075614</td>\n",
       "      <td>1.107553</td>\n",
       "      <td>-0.182228</td>\n",
       "      <td>0.894062</td>\n",
       "      <td>0.311408</td>\n",
       "      <td>-0.223043</td>\n",
       "      <td>0.803421</td>\n",
       "      <td>0.799233</td>\n",
       "      <td>0.266539</td>\n",
       "      <td>-0.107081</td>\n",
       "      <td>0.079654</td>\n",
       "      <td>0.207388</td>\n",
       "      <td>-0.042034</td>\n",
       "      <td>-0.022996</td>\n",
       "      <td>-0.107792</td>\n",
       "      <td>0.008458</td>\n",
       "      <td>0.009633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1875000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  time      acc_x     acc_y      acc_z      gy_x       gy_y  \\\n",
       "0           0     0  27.356382  8.807207  19.465910  0.376992   0.869226   \n",
       "1           0     1  -0.054866  0.833464   0.820412 -0.282128  -0.093560   \n",
       "2           0     2   0.024046  0.315921   0.081086 -0.182551  -0.053585   \n",
       "3           0     3   0.065632  0.117634  -0.040874 -0.194863   0.154242   \n",
       "4           0     4   0.151477  0.300751   0.317742 -0.350724   0.494539   \n",
       "...       ...   ...        ...       ...        ...       ...        ...   \n",
       "1874995  3124   595   0.365037  0.011656   0.845701  0.080839   0.350395   \n",
       "1874996  3124   596  10.220817  5.476964   7.441373  3.605246  16.530576   \n",
       "1874997  3124   597   0.386337  0.177768  -0.080193 -0.192468  -0.033904   \n",
       "1874998  3124   598   0.728823  0.014037   0.350745  0.136284   1.281790   \n",
       "1874999  3124   599   0.886204  0.075614   1.107553 -0.182228   0.894062   \n",
       "\n",
       "              gy_z  acc_Energy  gy_Energy  gy_acc_Energy  acc_x_dt  acc_y_dt  \\\n",
       "0         0.150423    0.495681  -0.272719      -0.276391  0.000027  0.000298   \n",
       "1         0.011266    0.742974  -0.236152      -0.240632  0.416836 -0.118821   \n",
       "2        -0.003708    0.819822  -0.169815      -0.173080  0.086405  0.023750   \n",
       "3         0.005408    0.785669  -0.035229      -0.040560 -0.058780 -0.213920   \n",
       "4         0.154354    0.791528   0.021954       0.016872  0.039823  0.259227   \n",
       "...            ...         ...        ...            ...       ...       ...   \n",
       "1874995   0.112282   -0.138940   0.829394       0.823900  0.151679  0.037205   \n",
       "1874996  11.843241   -0.167578   0.814816       0.809618  0.150658 -0.000363   \n",
       "1874997  -0.227861   -0.151875   0.802027       0.797338  0.093524 -0.049283   \n",
       "1874998   0.403540   -0.175811   0.801880       0.797431  0.174681 -0.096564   \n",
       "1874999   0.311408   -0.223043   0.803421       0.799233  0.266539 -0.107081   \n",
       "\n",
       "         acc_z_dt   gy_x_dt   gy_y_dt   gy_z_dt  acc_Energy_dt  gy_Energy_dt  \\\n",
       "0       -0.000433  0.000347  0.000373  0.000273       0.000101      0.001505   \n",
       "1       -0.255054  0.032738 -0.349095  0.377085       0.564992      0.166566   \n",
       "2       -0.531727 -0.141582 -0.202368 -0.004887       0.175645      0.300944   \n",
       "3        0.285459  0.229520 -0.385106 -0.135647      -0.077915      0.609008   \n",
       "4       -0.055206  0.057320 -0.174917 -0.028047       0.013483      0.259626   \n",
       "...           ...       ...       ...       ...            ...           ...   \n",
       "1874995  0.119409 -0.108728 -0.027804 -0.009085      -0.142794      0.063329   \n",
       "1874996  0.265559 -0.027936  0.090560 -0.018412      -0.065316     -0.064300   \n",
       "1874997  0.260884  0.082744  0.123264 -0.152712       0.035970     -0.056225   \n",
       "1874998  0.071332  0.153722 -0.014412 -0.049662      -0.054574      0.000843   \n",
       "1874999  0.079654  0.207388 -0.042034 -0.022996      -0.107792      0.008458   \n",
       "\n",
       "         gy_acc_Energy_dt  \n",
       "0                0.001501  \n",
       "1                0.162871  \n",
       "2                0.306341  \n",
       "3                0.599518  \n",
       "4                0.260669  \n",
       "...                   ...  \n",
       "1874995          0.063674  \n",
       "1874996         -0.062949  \n",
       "1874997         -0.053918  \n",
       "1874998          0.001922  \n",
       "1874999          0.009633  \n",
       "\n",
       "[1875000 rows x 20 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875000, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(train.iloc[:,2:]).reshape(3125, 600, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3125, 600, 18)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3125, 61)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x=np.array(test.iloc[:,2:]).reshape(782, 600, -1)\n",
    "test_x.shape\n",
    "\n",
    "y = train_labels['label'].values\n",
    "y = tf.keras.utils.to_categorical(train_labels['label']) \n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standard scaling 적용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델링\n",
    "\n",
    "+ CNN, LSTM, CNN+LSTM 등 여러 구조 적용해보다가 CNN에서 Flatten 없이 Global average pooling 한 구조가 가장 성능이 좋아 채택했습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM,Bidirectional,Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from numpy.random import seed\n",
    "from tensorflow.keras.layers import Activation, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling1D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델 구조 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 600, 128)          20864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 300, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 300, 256)          295168    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 150, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 150, 128)          295040    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 61)                3965      \n",
      "=================================================================\n",
      "Total params: 639,805\n",
      "Trainable params: 639,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model= keras.Sequential()\n",
    "# model.add(Conv1D(filters=128, kernel_size=9, kernel_initializer='he_uniform' ,padding=\"same\",input_shape=X.shape[1:], activation=\"relu\"))\n",
    "# model.add(MaxPooling1D())\n",
    "# model.add(Conv1D(filters=256, kernel_size=9, padding=\"same\",input_shape=X.shape[1:], activation=\"relu\"))\n",
    "# model.add(MaxPooling1D())\n",
    "# model.add(Conv1D(filters=128, kernel_size=9, padding=\"same\",input_shape=X.shape[1:], activation=\"relu\"))\n",
    "# #model.add(MaxPooling1D())\n",
    "# #model.add(Conv1D(filters=64, kernel_size=9, padding=\"same\",input_shape=X.shape[1:], activation=\"relu\"))\n",
    "# model.add(GlobalAveragePooling1D())\n",
    "\n",
    "# #model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(128, activation=\"relu\"))\n",
    "# model.add(Dropout(rate=0.1))\n",
    "# model.add(Dense(64, activation=\"relu\"))\n",
    "# model.add(Dropout(rate=0.2))\n",
    "\n",
    "\n",
    "# #model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "# model.add(Dense(61, activation=\"softmax\"))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer = 'Adam', metrics='accuracy')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 600, 18)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 600, 128)          20864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 600, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 600, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 600, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 600, 256)          196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 600, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 600, 256)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 600, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 600, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 600, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 600, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 600, 128)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_4 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 61)                7869      \n",
      "=================================================================\n",
      "Total params: 326,077\n",
      "Trainable params: 325,053\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed(2021)\n",
    "tf.random.set_seed(2021)\n",
    "\n",
    "input_layer = keras.layers.Input(X.shape[1:])\n",
    "conv1 = keras.layers.Conv1D(filters=128, kernel_size=9, padding='same')(input_layer)\n",
    "conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "conv1 = keras.layers.Activation(activation='relu')(conv1)\n",
    "conv1 = keras.layers.Dropout(rate=0.3)(conv1)\n",
    "\n",
    "conv2 = keras.layers.Conv1D(filters=256, kernel_size=6, padding='same')(conv1)\n",
    "conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "conv2 = keras.layers.Activation('relu')(conv2)\n",
    "conv2 = keras.layers.Dropout(rate=0.4)(conv2)\n",
    "\n",
    "conv3 = keras.layers.Conv1D(128, kernel_size=3,padding='same')(conv2)\n",
    "conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "conv3 = keras.layers.Activation('relu')(conv3)\n",
    "conv3 = keras.layers.Dropout(rate=0.5)(conv3)\n",
    "\n",
    "gap = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "output_layer = keras.layers.Dense(61, activation='softmax')(gap)\n",
    "\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer = 'Adam', metrics='accuracy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10-fold StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 5s 213ms/step - loss: 3.4091 - accuracy: 0.3740 - val_loss: 6.1116 - val_accuracy: 0.0288\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 2.3918 - accuracy: 0.5168 - val_loss: 4.0041 - val_accuracy: 0.0944\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 3s 176ms/step - loss: 2.0298 - accuracy: 0.5388 - val_loss: 2.5794 - val_accuracy: 0.4800\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 1.8565 - accuracy: 0.5620 - val_loss: 1.8786 - val_accuracy: 0.5568\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 3s 174ms/step - loss: 1.7284 - accuracy: 0.5800 - val_loss: 1.8508 - val_accuracy: 0.5600\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.6198 - accuracy: 0.6024 - val_loss: 2.0182 - val_accuracy: 0.5648\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 3s 176ms/step - loss: 1.5231 - accuracy: 0.6192 - val_loss: 1.8901 - val_accuracy: 0.5536\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 3s 185ms/step - loss: 1.4243 - accuracy: 0.6368 - val_loss: 1.8708 - val_accuracy: 0.5776\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 1.3479 - accuracy: 0.6588 - val_loss: 1.8127 - val_accuracy: 0.5808\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 1.2712 - accuracy: 0.6724 - val_loss: 1.8406 - val_accuracy: 0.5712\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 3s 173ms/step - loss: 1.2106 - accuracy: 0.6780 - val_loss: 1.6556 - val_accuracy: 0.5984\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 3s 185ms/step - loss: 1.1488 - accuracy: 0.6972 - val_loss: 1.4667 - val_accuracy: 0.6448\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 1.0986 - accuracy: 0.7136 - val_loss: 1.4552 - val_accuracy: 0.6480\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 3s 184ms/step - loss: 1.0337 - accuracy: 0.7288 - val_loss: 1.2611 - val_accuracy: 0.6688\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 3s 173ms/step - loss: 0.9806 - accuracy: 0.7448 - val_loss: 1.2495 - val_accuracy: 0.6912\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.9257 - accuracy: 0.7596 - val_loss: 1.1601 - val_accuracy: 0.7248\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 3s 174ms/step - loss: 0.8774 - accuracy: 0.7644 - val_loss: 1.1452 - val_accuracy: 0.6992\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 3s 184ms/step - loss: 0.8364 - accuracy: 0.7800 - val_loss: 1.1604 - val_accuracy: 0.6896\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 3s 173ms/step - loss: 0.7997 - accuracy: 0.7816 - val_loss: 1.0420 - val_accuracy: 0.7264\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 0.7692 - accuracy: 0.7964 - val_loss: 0.9976 - val_accuracy: 0.7232\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 3s 173ms/step - loss: 0.7416 - accuracy: 0.7996 - val_loss: 1.0151 - val_accuracy: 0.7440\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 0.7040 - accuracy: 0.8100 - val_loss: 0.9593 - val_accuracy: 0.7440\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 3s 173ms/step - loss: 0.6780 - accuracy: 0.8156 - val_loss: 0.9525 - val_accuracy: 0.7568\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.6552 - accuracy: 0.8160 - val_loss: 0.8745 - val_accuracy: 0.7456\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 3s 176ms/step - loss: 0.6354 - accuracy: 0.8216 - val_loss: 0.8682 - val_accuracy: 0.7792\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 3s 184ms/step - loss: 0.6324 - accuracy: 0.8192 - val_loss: 0.8384 - val_accuracy: 0.7872\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 3s 174ms/step - loss: 0.5962 - accuracy: 0.8348 - val_loss: 0.8899 - val_accuracy: 0.7744\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 3s 184ms/step - loss: 0.5830 - accuracy: 0.8340 - val_loss: 0.8461 - val_accuracy: 0.7744\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 3s 173ms/step - loss: 0.5532 - accuracy: 0.8560 - val_loss: 0.7696 - val_accuracy: 0.8032\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 3s 184ms/step - loss: 0.5352 - accuracy: 0.8452 - val_loss: 0.8695 - val_accuracy: 0.7536\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 3s 175ms/step - loss: 0.5269 - accuracy: 0.8524 - val_loss: 0.7387 - val_accuracy: 0.8048\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 0.5049 - accuracy: 0.8664 - val_loss: 0.7370 - val_accuracy: 0.8048\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 3s 173ms/step - loss: 0.4859 - accuracy: 0.8612 - val_loss: 0.7209 - val_accuracy: 0.8096\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 0.4708 - accuracy: 0.8684 - val_loss: 0.7152 - val_accuracy: 0.8240\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 3s 174ms/step - loss: 0.4596 - accuracy: 0.8708 - val_loss: 0.6551 - val_accuracy: 0.8144\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.4582 - accuracy: 0.8756 - val_loss: 0.6865 - val_accuracy: 0.8144\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 3s 173ms/step - loss: 0.4705 - accuracy: 0.8676 - val_loss: 0.7150 - val_accuracy: 0.8080\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.4546 - accuracy: 0.8680 - val_loss: 0.6302 - val_accuracy: 0.8224\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 3s 174ms/step - loss: 0.4193 - accuracy: 0.8892 - val_loss: 0.6508 - val_accuracy: 0.8288\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 3s 190ms/step - loss: 0.4064 - accuracy: 0.8896 - val_loss: 0.6522 - val_accuracy: 0.8224\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 3s 173ms/step - loss: 0.4048 - accuracy: 0.8892 - val_loss: 0.6066 - val_accuracy: 0.8208\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 0.3906 - accuracy: 0.8904 - val_loss: 0.6171 - val_accuracy: 0.8144\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 3s 173ms/step - loss: 0.3843 - accuracy: 0.8952 - val_loss: 0.6126 - val_accuracy: 0.8272\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 0.3706 - accuracy: 0.8944 - val_loss: 0.6356 - val_accuracy: 0.8080\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 3s 173ms/step - loss: 0.3700 - accuracy: 0.8980 - val_loss: 0.6699 - val_accuracy: 0.7904\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 0.3493 - accuracy: 0.9024 - val_loss: 0.5898 - val_accuracy: 0.8304\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 3s 176ms/step - loss: 0.3351 - accuracy: 0.9100 - val_loss: 0.5746 - val_accuracy: 0.8272\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 3s 187ms/step - loss: 0.3304 - accuracy: 0.9100 - val_loss: 0.5591 - val_accuracy: 0.8224\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 3s 174ms/step - loss: 0.3230 - accuracy: 0.9120 - val_loss: 0.5505 - val_accuracy: 0.8320\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 3s 184ms/step - loss: 0.3146 - accuracy: 0.9144 - val_loss: 0.5551 - val_accuracy: 0.8240\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 3s 177ms/step - loss: 0.3229 - accuracy: 0.9112 - val_loss: 0.5517 - val_accuracy: 0.8400\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 0.3152 - accuracy: 0.9216 - val_loss: 0.5473 - val_accuracy: 0.8272\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 3s 176ms/step - loss: 0.3006 - accuracy: 0.9212 - val_loss: 0.5480 - val_accuracy: 0.8304\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.3036 - accuracy: 0.9228 - val_loss: 0.5444 - val_accuracy: 0.8304\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 3s 175ms/step - loss: 0.3031 - accuracy: 0.9196 - val_loss: 0.5374 - val_accuracy: 0.8384\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.3033 - accuracy: 0.9212 - val_loss: 0.5461 - val_accuracy: 0.8400\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 3s 175ms/step - loss: 0.3010 - accuracy: 0.9228 - val_loss: 0.5556 - val_accuracy: 0.8384\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 3s 186ms/step - loss: 0.2937 - accuracy: 0.9248 - val_loss: 0.5381 - val_accuracy: 0.8272\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 3s 175ms/step - loss: 0.2968 - accuracy: 0.9200 - val_loss: 0.5540 - val_accuracy: 0.8352\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.2788 - accuracy: 0.9308 - val_loss: 0.5241 - val_accuracy: 0.8288\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 3s 176ms/step - loss: 0.2775 - accuracy: 0.9300 - val_loss: 0.5153 - val_accuracy: 0.8352\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 0.2692 - accuracy: 0.9364 - val_loss: 0.5168 - val_accuracy: 0.8384\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 3s 174ms/step - loss: 0.2668 - accuracy: 0.9272 - val_loss: 0.5196 - val_accuracy: 0.8336\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 0.2651 - accuracy: 0.9356 - val_loss: 0.5120 - val_accuracy: 0.8368\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 0.2668 - accuracy: 0.9312 - val_loss: 0.5286 - val_accuracy: 0.8320\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 0.2666 - accuracy: 0.9312 - val_loss: 0.5037 - val_accuracy: 0.8416\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 3s 174ms/step - loss: 0.2653 - accuracy: 0.9300 - val_loss: 0.5108 - val_accuracy: 0.8400\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 0.2589 - accuracy: 0.9356 - val_loss: 0.5047 - val_accuracy: 0.8368\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 3s 173ms/step - loss: 0.2551 - accuracy: 0.9412 - val_loss: 0.5142 - val_accuracy: 0.8368\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.2562 - accuracy: 0.9392 - val_loss: 0.5137 - val_accuracy: 0.8320\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 3s 172ms/step - loss: 0.2527 - accuracy: 0.9348 - val_loss: 0.5042 - val_accuracy: 0.8400\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.2439 - accuracy: 0.9408 - val_loss: 0.5047 - val_accuracy: 0.8352\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 3s 175ms/step - loss: 0.2487 - accuracy: 0.9424 - val_loss: 0.5087 - val_accuracy: 0.8352\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.2441 - accuracy: 0.9428 - val_loss: 0.5010 - val_accuracy: 0.8400\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 3s 173ms/step - loss: 0.2435 - accuracy: 0.9400 - val_loss: 0.5020 - val_accuracy: 0.8400\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 3s 185ms/step - loss: 0.2410 - accuracy: 0.9420 - val_loss: 0.5035 - val_accuracy: 0.8384\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 3s 173ms/step - loss: 0.2431 - accuracy: 0.9416 - val_loss: 0.5039 - val_accuracy: 0.8384\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 0.2437 - accuracy: 0.9384 - val_loss: 0.5043 - val_accuracy: 0.8384\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 3s 175ms/step - loss: 0.2340 - accuracy: 0.9448 - val_loss: 0.4964 - val_accuracy: 0.8400\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 3s 184ms/step - loss: 0.2341 - accuracy: 0.9444 - val_loss: 0.4971 - val_accuracy: 0.8432\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 3s 175ms/step - loss: 0.2380 - accuracy: 0.9412 - val_loss: 0.4987 - val_accuracy: 0.8400\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 0.2450 - accuracy: 0.9416 - val_loss: 0.4958 - val_accuracy: 0.8432\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 3s 172ms/step - loss: 0.2372 - accuracy: 0.9436 - val_loss: 0.4981 - val_accuracy: 0.8432\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 0.2355 - accuracy: 0.9424 - val_loss: 0.4965 - val_accuracy: 0.8448\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 3s 173ms/step - loss: 0.2329 - accuracy: 0.9440 - val_loss: 0.4981 - val_accuracy: 0.8448\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 3s 187ms/step - loss: 0.2359 - accuracy: 0.9444 - val_loss: 0.4981 - val_accuracy: 0.8432\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 3s 174ms/step - loss: 0.2351 - accuracy: 0.9432 - val_loss: 0.4967 - val_accuracy: 0.8464\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 3s 184ms/step - loss: 0.2367 - accuracy: 0.9452 - val_loss: 0.4968 - val_accuracy: 0.8448\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 3s 175ms/step - loss: 0.2297 - accuracy: 0.9464 - val_loss: 0.4974 - val_accuracy: 0.8448\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 0.2323 - accuracy: 0.9452 - val_loss: 0.4959 - val_accuracy: 0.8448\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 3s 176ms/step - loss: 0.2287 - accuracy: 0.9440 - val_loss: 0.4955 - val_accuracy: 0.8448\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 0.2311 - accuracy: 0.9452 - val_loss: 0.4951 - val_accuracy: 0.8432\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 3s 174ms/step - loss: 0.2293 - accuracy: 0.9460 - val_loss: 0.4952 - val_accuracy: 0.8432\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 3s 184ms/step - loss: 0.2331 - accuracy: 0.9468 - val_loss: 0.4947 - val_accuracy: 0.8464\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 3s 172ms/step - loss: 0.2297 - accuracy: 0.9436 - val_loss: 0.4939 - val_accuracy: 0.8432\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 0.2258 - accuracy: 0.9472 - val_loss: 0.4946 - val_accuracy: 0.8448\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 3s 173ms/step - loss: 0.2318 - accuracy: 0.9432 - val_loss: 0.4942 - val_accuracy: 0.8448\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 3s 186ms/step - loss: 0.2334 - accuracy: 0.9444 - val_loss: 0.4946 - val_accuracy: 0.8432\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 3s 173ms/step - loss: 0.2257 - accuracy: 0.9464 - val_loss: 0.4948 - val_accuracy: 0.8432\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 3s 184ms/step - loss: 0.2284 - accuracy: 0.9444 - val_loss: 0.4945 - val_accuracy: 0.8432\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits = 10, random_state = 123, shuffle = True)\n",
    "reLR = ReduceLROnPlateau(patience = 4,verbose = 1,factor = 0.5) \n",
    "es =EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(X, y, epochs = 100, verbose=1, batch_size=100, validation_split = 0.2, callbacks=[es,reLR])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[4032,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-03e88fb7ef26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    970\u001b[0m                                                 input_list)\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1105\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1106\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1108\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    838\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    876\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2623\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2625\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2626\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2627\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                        'should be defined. Found `None`.')\n\u001b[1;32m   1190\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlast_dim\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m     self.kernel = self.add_weight(\n\u001b[0m\u001b[1;32m   1192\u001b[0m         \u001b[0;34m'kernel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mcaching_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m     variable = self._add_variable_with_custom_getter(\n\u001b[0m\u001b[1;32m    640\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;31m# \"best effort\" to set the initializer with the highest restore UID.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_initializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m     new_variable = getter(\n\u001b[0m\u001b[1;32m    811\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    125\u001b[0m   \u001b[0;31m# can remove the V1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0mvariable_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m   return tf_variables.VariableV1(\n\u001b[0m\u001b[1;32m    128\u001b[0m       \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maggregation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m       \u001b[0maggregation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariableAggregation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     return previous_getter(\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                         shape=None):\n\u001b[1;32m    198\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2610\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2611\u001b[0m     \u001b[0mdistribute_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"distribute_strategy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2612\u001b[0;31m     return resource_variable_ops.ResourceVariable(\n\u001b[0m\u001b[1;32m   2613\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2614\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1582\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1584\u001b[0;31m       self._init_from_args(\n\u001b[0m\u001b[1;32m   1585\u001b[0m           \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1720\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1722\u001b[0;31m               \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1723\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1724\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/initializers/initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/initializers/initializers_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m    976\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m     return op(\n\u001b[0m\u001b[1;32m    979\u001b[0m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    307\u001b[0m           shape, minval, maxval, seed=seed1, seed2=seed2, name=name)\n\u001b[1;32m    308\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m       result = gen_random_ops.random_uniform(\n\u001b[0m\u001b[1;32m    310\u001b[0m           shape, dtype, seed=seed1, seed2=seed2)\n\u001b[1;32m    311\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mminval_is_zero\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/gen_random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[1;32m    719\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6895\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6896\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6897\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6898\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py38_tensorflow/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[4032,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]"
     ]
    }
   ],
   "source": [
    "# prediction=0\n",
    "# folds=5\n",
    "# repeats=50\n",
    "# epochsize=50\n",
    "# drop=0.5\n",
    "# kfold = KFold(n_splits=folds, shuffle=True)\n",
    "\n",
    "# for k in range(repeats):\n",
    "#   for train_ind, test_ind in kfold.split(X, y):\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv1D (kernel_size=60, filters=256, strides=3, padding='valid',\n",
    "#                     kernel_initializer='he_uniform', input_shape=X.shape[1:],\n",
    "#                     activation='relu'))\n",
    "#     model.add(MaxPooling1D(1, padding = 'valid'))\n",
    "\n",
    "#     model.add(Conv1D(kernel_size=60, filters=128, activation='relu'))\n",
    "#     model.add(MaxPooling1D(1, padding = 'valid'))\n",
    "\n",
    "#     model.add(Conv1D(kernel_size=60, filters=64, activation='relu'))\n",
    "#     model.add(MaxPooling1D(1, padding = 'valid'))\n",
    "\n",
    "#     model.add(BatchNormalization())\n",
    "\n",
    "#     model.add(Dropout(drop))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(1024, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "\n",
    "#     model.add(Dropout(drop))\n",
    "#     model.add(Dense(1024, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "\n",
    "#     model.add(Dropout(drop))\n",
    "#     model.add(Dense(1024, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "#     model.add(Dropout(drop))\n",
    "#     model.add(Dense(61))\n",
    "#     model.add(Activation('softmax'))\n",
    "\n",
    "#     adam = optimizers.Adam(lr=0.0001)\n",
    "\n",
    "#     model.compile(loss='categorical_crossentropy',\n",
    "#                   optimizer=adam,\n",
    "#                   metrics=['accuracy'])\n",
    "    \n",
    "#     model.fit(np.array(X)[train_ind], y[train_ind], epochs=epochsize, batch_size=64,\n",
    "#               validation_data=(np.array(X)[test_ind], y[test_ind]))\n",
    "\n",
    "#     prediction += (model.predict(test_x)/(folds*repeats))\n",
    "\n",
    "# submission.iloc[:,1:]=prediction\n",
    "# submission.to_csv('py_answer1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 성능 확인 및 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 1s 13ms/step - loss: 0.2676 - accuracy: 0.9344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2676210403442383, 0.9344000220298767]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. 모델 평가하기\n",
    "model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_x)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.732821e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.287268e-36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.967757e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.006263e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>3902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>3903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>3904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>3905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.142778e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.345666e-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>782 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    0    1    2    3    4    5    6    7             8    9   10  \\\n",
       "0    3125  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  2.732821e-12  0.0  0.0   \n",
       "1    3126  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000e+00  0.0  0.0   \n",
       "2    3127  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  6.967757e-12  0.0  0.0   \n",
       "3    3128  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  8.006263e-01  0.0  0.0   \n",
       "4    3129  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000e+00  0.0  0.0   \n",
       "..    ...  ...  ...  ...  ...  ...  ...  ...  ...           ...  ...  ...   \n",
       "777  3902  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000e+00  0.0  0.0   \n",
       "778  3903  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000e+00  0.0  0.0   \n",
       "779  3904  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000e+00  0.0  0.0   \n",
       "780  3905  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.142778e-12  0.0  0.0   \n",
       "781  3906  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  2.345666e-23  0.0  0.0   \n",
       "\n",
       "      11   12   13   14   15   16   17   18            19   20   21   22   23  \\\n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.287268e-36  0.0  0.0  0.0  0.0   \n",
       "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000e+00  0.0  0.0  0.0  0.0   \n",
       "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000e+00  0.0  0.0  0.0  0.0   \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000e+00  0.0  0.0  0.0  0.0   \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000e+00  0.0  0.0  0.0  0.0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...           ...  ...  ...  ...  ...   \n",
       "777  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000e+00  0.0  0.0  0.0  0.0   \n",
       "778  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000e+00  0.0  0.0  0.0  0.0   \n",
       "779  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000e+00  0.0  0.0  0.0  0.0   \n",
       "780  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000e+00  0.0  0.0  0.0  0.0   \n",
       "781  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000e+00  0.0  0.0  0.0  0.0   \n",
       "\n",
       "     ...   36   37   38   39   40   41   42   43   44   45   46   47   48  \\\n",
       "0    ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1    ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2    ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3    ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4    ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "777  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "778  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "779  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "780  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "781  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      49        50   51   52   53   54   55   56   57   58   59   60  \n",
       "0    0.0  1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1    0.0  1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2    0.0  1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3    0.0  0.199374  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4    0.0  1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "..   ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "777  0.0  1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "778  0.0  1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "779  0.0  1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "780  0.0  1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "781  0.0  1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[782 rows x 62 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submission=pd.read_csv('./sample_submission.csv')\n",
    "submission.iloc[:,1:]=pred\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('sub_chuchu.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_tensorflow",
   "language": "python",
   "name": "conda-env-py38_tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
